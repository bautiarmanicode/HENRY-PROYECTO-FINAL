{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propuesta Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Análisis de Sentimiento de Reseñas\n",
    "\n",
    "Descripción:\n",
    "Analizar las reseñas de los usuarios para determinar el sentimiento (positivo, negativo, neutral).\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "Proporciona información valiosa sobre la percepción de los clientes.\n",
    "Permite a las empresas identificar problemas recurrentes y áreas de mejora.\n",
    "Ayuda a mejorar la satisfacción del cliente a través de respuestas proactivas.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "Requiere técnicas avanzadas de procesamiento de lenguaje natural (NLP).\n",
    "Puede ser difícil manejar el sarcasmo, la ironía y los contextos específicos.\n",
    "\n",
    "Utilidades para el Mercado:\n",
    "\n",
    "Mejora la gestión de la reputación online.\n",
    "Permite personalizar la comunicación con los clientes.\n",
    "Ayuda a desarrollar estrategias de marketing más efectivas.\n",
    "\n",
    "Carpeta de Datos Utilizados: review-estados review.json\n",
    "\n",
    "Posibles KPIs con este enfoque: Análisis de Sentimiento de Reseñas\n",
    "\n",
    "Objetivo: Mejorar la satisfacción del cliente a través de la gestión proactiva de comentarios negativos.\n",
    "\n",
    "Primer KPI: Reducción del número de reseñas con calificación inferior a 3 estrellas en un 20% trimestralmente.\n",
    "Métrica: Porcentaje de reseñas con calificación inferior a 3 estrellas.\n",
    "Objetivo: Aumentar la retención de clientes mediante la respuesta rápida a comentarios negativos.\n",
    "\n",
    "Segundo KPI: Incremento en la tasa de retención de clientes en un 5% después de implementar el sistema de análisis de sentimiento.\n",
    "Métrica: Tasa de retención de clientes.\n",
    "Objetivo: Mejorar la reputación online de la empresa a través de comentarios positivos.\n",
    "\n",
    "Tercer KPI: Aumento del promedio de calificación de la empresa en sitios de reseñas en línea en 0.5 puntos en un año.\n",
    "Métrica: Promedio de calificación de la empresa en sitios de reseñas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalación de Bibliotecas Necesarias\n",
    "pip install pandas textblob\n",
    "#Importación de Bibliotecas Necesarias\n",
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(file_path):\n",
    "    \"\"\"\n",
    "    Carga las reseñas desde un archivo JSON a un DataFrame de pandas.\n",
    "\n",
    "    :param file_path: Ruta al archivo JSON que contiene las reseñas.\n",
    "    :return: DataFrame con las reseñas.\n",
    "    \"\"\"\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    return df\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analiza el sentimiento de un texto dado.\n",
    "\n",
    "    :param text: Reseña en formato de texto.\n",
    "    :return: Polaridad del sentimiento (valor entre -1 y 1).\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def add_sentiment_column(df):\n",
    "    \"\"\"\n",
    "    Añade una columna de sentimiento al DataFrame.\n",
    "\n",
    "    :param df: DataFrame que contiene las reseñas.\n",
    "    :return: DataFrame con una columna adicional de sentimiento.\n",
    "    \"\"\"\n",
    "    df['sentiment'] = df['text'].apply(analyze_sentiment)\n",
    "    return df\n",
    "\n",
    "def save_results(df, output_path):\n",
    "    \"\"\"\n",
    "    Guarda el DataFrame con los resultados del análisis de sentimiento a un archivo CSV.\n",
    "\n",
    "    :param df: DataFrame que contiene las reseñas y los resultados del análisis de sentimiento.\n",
    "    :param output_path: Ruta al archivo CSV donde se guardarán los resultados.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el flujo completo del análisis de sentimiento.\n",
    "\n",
    "    1. Carga las reseñas desde un archivo JSON.\n",
    "    2. Analiza el sentimiento de cada reseña.\n",
    "    3. Guarda los resultados en un archivo CSV.\n",
    "    \"\"\"\n",
    "    # Ruta al archivo de entrada y al archivo de salida\n",
    "    input_file_path = 'review.json'\n",
    "    output_file_path = 'sentiment_analysis_results.csv'\n",
    "    \n",
    "    # Cargar reseñas\n",
    "    reviews_df = load_reviews(input_file_path)\n",
    "    \n",
    "    # Añadir columna de sentimiento\n",
    "    reviews_df = add_sentiment_column(reviews_df)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    save_results(reviews_df, output_file_path)\n",
    "    print(f\"Resultados guardados en {output_file_path}\")\n",
    "\n",
    "# Ejecutar la función principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recomendador de Negocios\n",
    "\n",
    "Descripción:\n",
    "\n",
    "Crear un sistema de recomendación que sugiera negocios a los usuarios basándose en sus reseñas pasadas y las de otros usuarios similares.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "Aumenta la satisfacción del cliente al ofrecer recomendaciones personalizadas.\n",
    "Incrementa la probabilidad de ventas cruzadas y repetitivas.\n",
    "Mejora la experiencia del usuario en plataformas como Yelp y Google Maps.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "Requiere un gran volumen de datos para ser preciso.\n",
    "Puede ser complicado de implementar y mantener.\n",
    "\n",
    "Utilidades para el Mercado:\n",
    "\n",
    "Plataformas de reseñas y directorios de negocios pueden retener usuarios por más tiempo.\n",
    "Ayuda a los negocios a llegar a clientes potenciales de manera más efectiva.\n",
    "\n",
    "Carpeta de Datos Utilizados: user.parquet review.json business.pkl\n",
    "\n",
    "Posibles KPIs: Recomendador de Negocios\n",
    "\n",
    "Objetivo: Incrementar las conversiones de visitas a negocios recomendados.\n",
    "\n",
    "Primer KPI: Aumento del número de conversiones en ventas en un 10% mensualmente a través de recomendaciones personalizadas.\n",
    "Métrica: Tasa de conversión de visitas a ventas.\n",
    "Objetivo: Mejorar la satisfacción del cliente con las recomendaciones de productos o servicios.\n",
    "\n",
    "Segundo KPI: Aumento del porcentaje de clientes satisfechos con las recomendaciones en un 15% en seis meses.\n",
    "Métrica: Porcentaje de clientes satisfechos con las recomendaciones.\n",
    "Objetivo: Optimizar el rendimiento de marketing mediante recomendaciones precisas.\n",
    "\n",
    "Tercer KPI: Reducción del costo de adquisición de clientes (CAC) en un 10% utilizando recomendaciones personalizadas.\n",
    "Métrica: Costo de adquisición de clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalamos lo necesario\n",
    "pip install pandas scikit-surprise\n",
    "#Importamos lo necesario\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(file_path):\n",
    "    \"\"\"\n",
    "    Carga las reseñas desde un archivo JSON a un DataFrame de pandas.\n",
    "\n",
    "    :param file_path: Ruta al archivo JSON que contiene las reseñas.\n",
    "    :return: DataFrame con las reseñas.\n",
    "    \"\"\"\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Prepara los datos para el sistema de recomendación.\n",
    "\n",
    "    :param df: DataFrame que contiene las reseñas.\n",
    "    :return: Dataset de Surprise listo para el entrenamiento y evaluación.\n",
    "    \"\"\"\n",
    "    # Seleccionamos solo las columnas necesarias\n",
    "    df = df[['user_id', 'business_id', 'stars']]\n",
    "    \n",
    "    # Definimos el esquema de los datos\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    \n",
    "    # Creamos el dataset de Surprise\n",
    "    data = Dataset.load_from_df(df, reader)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def build_and_evaluate_model(data):\n",
    "    \"\"\"\n",
    "    Construye y evalúa el modelo de recomendación.\n",
    "\n",
    "    :param data: Dataset de Surprise listo para el entrenamiento y evaluación.\n",
    "    :return: Algoritmo entrenado y precisión del modelo.\n",
    "    \"\"\"\n",
    "    # Dividimos el dataset en entrenamiento y prueba\n",
    "    trainset, testset = train_test_split(data, test_size=0.25)\n",
    "    \n",
    "    # Definimos el algoritmo KNN básico\n",
    "    algo = KNNBasic()\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Predecimos los datos de prueba\n",
    "    predictions = algo.test(testset)\n",
    "    \n",
    "    # Calculamos la precisión del modelo\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    \n",
    "    return algo, rmse\n",
    "\n",
    "def get_top_n_recommendations(algo, user_id, n=10):\n",
    "    \"\"\"\n",
    "    Obtiene las top N recomendaciones para un usuario dado.\n",
    "\n",
    "    :param algo: Algoritmo entrenado de Surprise.\n",
    "    :param user_id: ID del usuario para el cual se desean obtener las recomendaciones.\n",
    "    :param n: Número de recomendaciones a obtener.\n",
    "    :return: Lista de tuples con las recomendaciones (business_id, estimated_rating).\n",
    "    \"\"\"\n",
    "    # Obtenemos todos los ítems\n",
    "    all_items = algo.trainset.all_items()\n",
    "    \n",
    "    # Convertimos los ítems a sus IDs originales\n",
    "    items = [algo.trainset.to_raw_iid(iid) for iid in all_items]\n",
    "    \n",
    "    # Predecimos las calificaciones para todos los ítems no vistos por el usuario\n",
    "    predictions = [algo.predict(user_id, iid) for iid in items]\n",
    "    \n",
    "    # Ordenamos las predicciones por la calificación estimada\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Retornamos las top N recomendaciones\n",
    "    top_n = [(pred.iid, pred.est) for pred in predictions[:n]]\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el flujo completo del sistema de recomendación.\n",
    "\n",
    "    1. Carga las reseñas desde un archivo JSON.\n",
    "    2. Prepara los datos para el sistema de recomendación.\n",
    "    3. Construye y evalúa el modelo de recomendación.\n",
    "    4. Obtiene y muestra las top N recomendaciones para un usuario específico.\n",
    "    \"\"\"\n",
    "    # Ruta al archivo de entrada\n",
    "    input_file_path = 'review.json'\n",
    "    \n",
    "    # Cargar reseñas\n",
    "    reviews_df = load_reviews(input_file_path)\n",
    "    \n",
    "    # Preparar datos\n",
    "    data = prepare_data(reviews_df)\n",
    "    \n",
    "    # Construir y evaluar modelo\n",
    "    algo, rmse = build_and_evaluate_model(data)\n",
    "    print(f\"Precisión del modelo (RMSE): {rmse}\")\n",
    "    \n",
    "    # Obtener y mostrar recomendaciones para un usuario específico\n",
    "    user_id = 'Ha3iJu77CxlrFm-vQRs_8g'  # Cambia este ID por el que desees\n",
    "    top_n_recommendations = get_top_n_recommendations(algo, user_id)\n",
    "    print(f\"Top {len(top_n_recommendations)} recomendaciones para el usuario {user_id}:\")\n",
    "    for business_id, rating in top_n_recommendations:\n",
    "        print(f\"Business ID: {business_id}, Estimated Rating: {rating}\")\n",
    "\n",
    "# Ejecutar la función principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Segmentación de Clientes\n",
    "\n",
    "Descripción:\n",
    "\n",
    "Agrupar clientes en diferentes segmentos basados en su comportamiento, demografía y patrones de reseñas.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "Permite personalizar las campañas de marketing.\n",
    "Identifica segmentos de alto valor para estrategias específicas.\n",
    "Mejora la retención de clientes y la lealtad.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "Requiere análisis detallados y algoritmos de clustering.\n",
    "Los segmentos pueden cambiar con el tiempo, requiriendo actualizaciones periódicas.\n",
    "\n",
    "Utilidades para el Mercado:\n",
    "\n",
    "Empresas pueden desarrollar productos y servicios específicos para diferentes segmentos.\n",
    "Optimización de recursos en campañas de marketing.\n",
    "\n",
    "Carpeta de Datos Utilizados: user.parquet review.json\n",
    "\n",
    "Posibles KPIs: Segmentación de Clientes\n",
    "\n",
    "Objetivo: Mejorar la personalización de ofertas basadas en el comportamiento del cliente.\n",
    "\n",
    "Primer KPI: Aumento del valor promedio de compra por cliente en un 15% después de implementar la segmentación avanzada.\n",
    "Métrica: Valor promedio de compra por cliente.\n",
    "Objetivo: Aumentar la lealtad del cliente mediante ofertas personalizadas.\n",
    "\n",
    "Segundo KPI: Incremento del número de clientes recurrentes en un 10% trimestralmente después de la implementación de la segmentación de clientes.\n",
    "Métrica: Porcentaje de clientes recurrentes.\n",
    "Objetivo: Reducir el abandono de carritos de compra a través de recomendaciones personalizadas.\n",
    "\n",
    "Tercer KPI: Disminución de la tasa de abandono de carritos en un 5% después de la implementación del modelo de segmentación de clientes.\n",
    "Métrica: Tasa de abandono de carritos de compra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalamos lo Necesario\n",
    "pip install pandas scikit-learn\n",
    "#Importamos lo necesario\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_data(file_path):\n",
    "    \"\"\"\n",
    "    Carga los datos de los usuarios desde un archivo parquet a un DataFrame de pandas.\n",
    "\n",
    "    :param file_path: Ruta al archivo parquet que contiene los datos de los usuarios.\n",
    "    :return: DataFrame con los datos de los usuarios.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(file_path)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesa los datos de los usuarios para la segmentación.\n",
    "\n",
    "    :param df: DataFrame que contiene los datos de los usuarios.\n",
    "    :return: DataFrame preprocesado.\n",
    "    \"\"\"\n",
    "    # Seleccionamos solo las columnas relevantes para la segmentación\n",
    "    df = df[['review_count', 'useful', 'funny', 'cool', 'fans', 'average_stars', 'compliment_hot', \n",
    "             'compliment_more', 'compliment_profile', 'compliment_cute', 'compliment_list', \n",
    "             'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', \n",
    "             'compliment_writer', 'compliment_photos']]\n",
    "    \n",
    "    # Estandarizamos los datos\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    \"\"\"\n",
    "    Encuentra el número óptimo de clusters usando el método del codo.\n",
    "\n",
    "    :param data: Datos preprocesados.\n",
    "    :param max_k: Número máximo de clusters a considerar.\n",
    "    \"\"\"\n",
    "    iters = range(1, max_k+1)\n",
    "    sse = []\n",
    "    for k in iters:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        sse.append(kmeans.inertia_)\n",
    "        print(f'Fit {k} clusters')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(iters, sse, marker='o')\n",
    "    plt.xlabel('Número de Clusters')\n",
    "    plt.ylabel('SSE')\n",
    "    plt.title('Método del Codo para Encontrar el Número Óptimo de Clusters')\n",
    "    plt.show()\n",
    "\n",
    "def segment_customers(data, n_clusters):\n",
    "    \"\"\"\n",
    "    Segmenta los clientes utilizando K-Means.\n",
    "\n",
    "    :param data: Datos preprocesados.\n",
    "    :param n_clusters: Número de clusters.\n",
    "    :return: Modelo KMeans entrenado y etiquetas de los clusters.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    return kmeans, labels\n",
    "\n",
    "def add_cluster_labels(df, labels):\n",
    "    \"\"\"\n",
    "    Añade las etiquetas de los clusters al DataFrame original.\n",
    "\n",
    "    :param df: DataFrame original.\n",
    "    :param labels: Etiquetas de los clusters.\n",
    "    :return: DataFrame con las etiquetas de los clusters.\n",
    "    \"\"\"\n",
    "    df['cluster'] = labels\n",
    "    return df\n",
    "\n",
    "def visualize_clusters(df):\n",
    "    \"\"\"\n",
    "    Visualiza los clusters utilizando un par de variables seleccionadas.\n",
    "\n",
    "    :param df: DataFrame que contiene los datos de los usuarios y las etiquetas de los clusters.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='average_stars', y='review_count', hue='cluster', data=df, palette='viridis')\n",
    "    plt.title('Visualización de Clusters')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el flujo completo de segmentación de clientes.\n",
    "\n",
    "    1. Carga los datos de los usuarios desde un archivo parquet.\n",
    "    2. Preprocesa los datos de los usuarios.\n",
    "    3. Encuentra el número óptimo de clusters.\n",
    "    4. Segmenta los clientes utilizando K-Means.\n",
    "    5. Añade las etiquetas de los clusters al DataFrame original.\n",
    "    6. Visualiza los clusters.\n",
    "    \"\"\"\n",
    "    # Ruta al archivo de entrada\n",
    "    input_file_path = 'user.parquet'\n",
    "    \n",
    "    # Cargar datos de los usuarios\n",
    "    users_df = load_user_data(input_file_path)\n",
    "    \n",
    "    # Preprocesar datos\n",
    "    data_scaled = preprocess_data(users_df)\n",
    "    \n",
    "    # Encontrar el número óptimo de clusters\n",
    "    find_optimal_clusters(data_scaled, max_k=10)\n",
    "    \n",
    "    # Segmentar clientes\n",
    "    n_clusters = 4  # Elige el número óptimo de clusters basado en el método del codo\n",
    "    kmeans_model, cluster_labels = segment_customers(data_scaled, n_clusters)\n",
    "    \n",
    "    # Añadir etiquetas de los clusters al DataFrame original\n",
    "    users_df_with_clusters = add_cluster_labels(users_df, cluster_labels)\n",
    "    \n",
    "    # Visualizar clusters\n",
    "    visualize_clusters(users_df_with_clusters)\n",
    "\n",
    "# Ejecutar la función principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Predicción de Cierre de Negocios\n",
    "\n",
    "Descripción:\n",
    "\n",
    "Predecir la probabilidad de que un negocio cierre basándose en diferentes variables como reseñas, ratings, número de check-ins, etc.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "Permite a los negocios tomar medidas preventivas.\n",
    "Ayuda a inversores y analistas a evaluar el riesgo.\n",
    "Proporciona información para políticas de soporte y financiación.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "Puede generar falsos positivos y negativos.\n",
    "Requiere modelos de clasificación robustos.\n",
    "\n",
    "Utilidades para el Mercado:\n",
    "\n",
    "Ayuda a mejorar la estabilidad del mercado.\n",
    "Proporciona insights valiosos para consultores y gestores de negocios.\n",
    "\n",
    "Carpeta de Datos Utilizados: business.pkl checkin.json review.json\n",
    "\n",
    "Posibles KPIs: Predicción de Cierre de Negocios\n",
    "\n",
    "Objetivo: Optimizar la gestión de riesgos mediante la predicción de cierre de negocios.\n",
    "\n",
    "Primer KPI: Reducción del riesgo de cierre de negocios en un 15% anualmente utilizando modelos predictivos.\n",
    "Métrica: Riesgo de cierre de negocios.\n",
    "Objetivo: Mejorar la planificación financiera a través de predicciones precisas de ingresos.\n",
    "\n",
    "Segundo KPI: Aumento de la precisión de las predicciones de ingresos en un 10% trimestralmente con modelos de predicción de cierre de negocios.\n",
    "Métrica: Precisión de las predicciones de ingresos.\n",
    "Objetivo: Reducir los costos operativos mediante la optimización de recursos en negocios con riesgo de cierre.\n",
    "\n",
    "Tercer KPI: Disminución del costo operativo en negocios con riesgo de cierre en un 5% después de implementar estrategias basadas en predicciones.\n",
    "Métrica: Costo operativo en negocios con riesgo de cierre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalamos lo necesario\n",
    "pip install pandas scikit-learn\n",
    "#Importamos lo necesario\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_business_data(file_path):\n",
    "    \"\"\"\n",
    "    Carga los datos de los negocios desde un archivo pickle a un DataFrame de pandas.\n",
    "\n",
    "    :param file_path: Ruta al archivo pickle que contiene los datos de los negocios.\n",
    "    :return: DataFrame con los datos de los negocios.\n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(file_path)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesa los datos de los negocios para la predicción.\n",
    "\n",
    "    :param df: DataFrame que contiene los datos de los negocios.\n",
    "    :return: DataFrame preprocesado y etiquetas.\n",
    "    \"\"\"\n",
    "    # Seleccionamos solo las columnas relevantes para la predicción\n",
    "    df = df[['review_count', 'stars', 'is_open', 'attributes', 'categories']]\n",
    "    \n",
    "    # Convertimos columnas categóricas a dummies\n",
    "    df = pd.get_dummies(df, columns=['attributes', 'categories'], drop_first=True)\n",
    "    \n",
    "    # Separar características y etiquetas\n",
    "    X = df.drop('is_open', axis=1)\n",
    "    y = df['is_open']\n",
    "    \n",
    "    # Estandarizamos los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, y\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"\n",
    "    Entrena un modelo de Regresión Logística para predecir el cierre de negocios.\n",
    "\n",
    "    :param X: Características preprocesadas.\n",
    "    :param y: Etiquetas (objetivo).\n",
    "    :return: Modelo entrenado.\n",
    "    \"\"\"\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Exactitud:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el flujo completo de predicción de cierre de negocios.\n",
    "\n",
    "    1. Carga los datos de los negocios desde un archivo pickle.\n",
    "    2. Preprocesa los datos de los negocios.\n",
    "    3. Entrena un modelo de Regresión Logística para predecir el cierre de negocios.\n",
    "    \"\"\"\n",
    "    # Ruta al archivo de entrada\n",
    "    input_file_path = 'business.pkl'\n",
    "    \n",
    "    # Cargar datos de los negocios\n",
    "    business_df = load_business_data(input_file_path)\n",
    "    \n",
    "    # Preprocesar datos\n",
    "    X, y = preprocess_data(business_df)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model = train_model(X, y)\n",
    "\n",
    "# Ejecutar la función principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Optimización de Horarios de Atención\n",
    "\n",
    "Descripción:\n",
    "\n",
    "Analizar los patrones de check-in y reseñas para optimizar los horarios de apertura y cierre de los negocios.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "Mejora la eficiencia operativa.\n",
    "Aumenta la satisfacción del cliente al estar abierto en horas más convenientes.\n",
    "Optimiza la asignación de recursos humanos.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "Requiere un análisis detallado de los patrones de tráfico de clientes.\n",
    "Puede ser complicado ajustar horarios en función de múltiples factores.\n",
    "\n",
    "Utilidades para el Mercado:\n",
    "\n",
    "Negocios pueden aumentar sus ingresos al estar abiertos en las horas más concurridas.\n",
    "Mejora la experiencia del cliente al reducir tiempos de espera.\n",
    "\n",
    "Carpeta de Datos Utilizados: checkin.json business.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
