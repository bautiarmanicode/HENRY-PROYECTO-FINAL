{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **ETL (Extract, Transform, Load)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üìÇProcesamiento del 1er archivo: `review`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Importamos las librer√≠as que vamos a usar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import warnings\n",
    "from data_utils import data_type_check\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ **Extraccion** de los datos y primera exploraci√≥n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se determina la cantidad de datos por porci√≥n\n",
    "chunk_s = 50000\n",
    "\n",
    "#ruta del archivo\n",
    "archivo = r\"C:\\Users\\argui\\OneDrive\\Escritorio\\ProyectoF-data\\review.json\"\n",
    "\n",
    "#Se carga el json en un dataframe \n",
    "df_re_1 = pd.read_json(archivo,lines=True,chunksize=chunk_s)\n",
    "\n",
    "#Se almacenan los df en una lista\n",
    "\n",
    "dfs = [] \n",
    "\n",
    "for df in df_re_1:\n",
    "          dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se trabajar√°n el archivo en 2 partes\n",
    "\n",
    "mitad = int(len(dfs)/2)\n",
    "dfs1 = dfs[:mitad]\n",
    "df_re_c1 = pd.concat(dfs1, axis=0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la funcion personalizada `data_type_check` invocada desde `data_utils.py` podemos observar:\n",
    "- Variables categ√≥ricas\n",
    "- Variables num√©ricas\n",
    "- Dimensiones del dataframe\n",
    "- Nulos\n",
    "- Tipos de datos\n",
    "- Informacion acerca de los datos faltantes o nulos de cada columna    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (3500000, 9)\n",
      "       columna  %_no_nulos  %_nulos  total_nulos       tipo_dato\n",
      "0    review_id       100.0      0.0            0          object\n",
      "1      user_id       100.0      0.0            0          object\n",
      "2  business_id       100.0      0.0            0          object\n",
      "3        stars       100.0      0.0            0           int64\n",
      "4       useful       100.0      0.0            0           int64\n",
      "5        funny       100.0      0.0            0           int64\n",
      "6         cool       100.0      0.0            0           int64\n",
      "7         text       100.0      0.0            0          object\n",
      "8         date       100.0      0.0            0  datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_re_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos una muestra del archivo para su optimizaci√≥n\n",
    "df_re_c1_sam = df_re_c1.sample(frac=0.06,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_re_c1_sam.to_parquet(r\"C:\\Users\\argui\\OneDrive\\Escritorio\\HENRY-PROYECTO-FINAL\\0 Dataset\\yelp_reviews.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÅ **TRANSFORM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
