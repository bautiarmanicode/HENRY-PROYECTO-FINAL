{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **ETL (Extract, Transform, Load)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üìÇProcesamiento del 1er archivo: `Google Maps/metadata-sitios/review-hawaii-`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Importamos las librer√≠as que vamos a usar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import data_utils   \n",
    "from data_utils import data_type_check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews Hawaii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ **Extraccion** de los datos y primera exploraci√≥n \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü Primero, vamos a convertir los datos de las rese√±as de Google Maps del estado de Hawaii, distribuidos en 11 archivos JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.139654e+20</td>\n",
       "      <td>manuel grimaldo</td>\n",
       "      <td>1591839903487</td>\n",
       "      <td>5</td>\n",
       "      <td>Great new upgrade</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x7c00159b5b1b1d25:0x8d2d85d4a758290e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.166558e+20</td>\n",
       "      <td>Enrique Lara</td>\n",
       "      <td>1568059018979</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x7c00159b5b1b1d25:0x8d2d85d4a758290e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.008341e+20</td>\n",
       "      <td>Gregory Donaldson</td>\n",
       "      <td>1594885588335</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x7c00159b5b1b1d25:0x8d2d85d4a758290e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.032072e+20</td>\n",
       "      <td>Brian Baker</td>\n",
       "      <td>1575951131613</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x7c00159b5b1b1d25:0x8d2d85d4a758290e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.085262e+20</td>\n",
       "      <td>Kam J</td>\n",
       "      <td>1573076723916</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x7c00159b5b1b1d25:0x8d2d85d4a758290e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id               name           time  rating               text  \\\n",
       "0  1.139654e+20    manuel grimaldo  1591839903487       5  Great new upgrade   \n",
       "1  1.166558e+20       Enrique Lara  1568059018979       5               None   \n",
       "2  1.008341e+20  Gregory Donaldson  1594885588335       5               None   \n",
       "3  1.032072e+20        Brian Baker  1575951131613       5               None   \n",
       "4  1.085262e+20              Kam J  1573076723916       3               None   \n",
       "\n",
       "   pics  resp                                gmap_id  \n",
       "0  None  None  0x7c00159b5b1b1d25:0x8d2d85d4a758290e  \n",
       "1  None  None  0x7c00159b5b1b1d25:0x8d2d85d4a758290e  \n",
       "2  None  None  0x7c00159b5b1b1d25:0x8d2d85d4a758290e  \n",
       "3  None  None  0x7c00159b5b1b1d25:0x8d2d85d4a758290e  \n",
       "4  None  None  0x7c00159b5b1b1d25:0x8d2d85d4a758290e  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se especifica la ruta que contiene la carpeta con los archivos:\n",
    "carpeta = \"../0 Dataset/review-Hawaii\"\n",
    "\n",
    "# Se crea lista vac√≠a donde se almacenar√°n los dataframes de cada archivo:\n",
    "reviews = []\n",
    "\n",
    "# Se recorre por todos los archivos en la carpeta:\n",
    "for filename in os.listdir(carpeta):\n",
    "    if filename.endswith('.json'):\n",
    "        # Se carga el archivo JSON en un DataFrame de Pandas:\n",
    "        filepath = os.path.join(carpeta, filename)\n",
    "        df = pd.read_json(filepath, lines = True)\n",
    "        \n",
    "        # Se agrega el DataFrame a la lista:\n",
    "        reviews.append(df)\n",
    "\n",
    "# Se combinan todos los DataFrames en uno solo usando pd.concat:\n",
    "df_rev_hawai = pd.concat(reviews, ignore_index=True)\n",
    "\n",
    "# Se chequean los primeros 5 valores:\n",
    "df_rev_hawai.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la funcion personalizada `data_type_check` invocada desde `data_utils.py` podemos observar:\n",
    "- Variables categ√≥ricas\n",
    "- Variables num√©ricas\n",
    "- Dimensiones del dataframe\n",
    "- Nulos\n",
    "- Tipos de datos\n",
    "- Informacion acerca de los datos faltantes o nulos de cada columna    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (1504347, 8)\n",
      "   columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0  user_id      100.00     0.00            0   float64\n",
      "1     name      100.00     0.00            0    object\n",
      "2     time      100.00     0.00            0     int64\n",
      "3   rating      100.00     0.00            0     int64\n",
      "4     text       56.68    43.32       651751    object\n",
      "5     pics        8.82    91.18      1371645    object\n",
      "6     resp        7.23    92.77      1395548    object\n",
      "7  gmap_id      100.00     0.00            0    object\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_rev_hawai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se exporta el archivo en formato parquet:\n",
    "df_rev_hawai.to_parquet(\"../0 Dataset/reviews_california.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
