{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **ETL (Extract, Transform, Load)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ipynb vamos a Extraer los archivos y cargarlos en parquet. Luego en otro archivo haremos las transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien vamos a estar utilizando la funcion personalizada personalizada `data_type_check` invocada desde `data_utils.py` para dejar un vistazo r√°pido del dataframe y  poder observar:\n",
    "- Variables categ√≥ricas\n",
    "- Variables num√©ricas\n",
    "- Dimensiones del dataframe\n",
    "- Nulos\n",
    "- Tipos de datos\n",
    "- Informacion acerca de los datos faltantes o nulos de cada columna    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Importamos las librer√≠as que vamos a usar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from data_utils import data_type_check, data_type_check_pkl\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### business.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150346 entries, 0 to 150345\n",
      "Data columns (total 28 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   business_id   150346 non-null  object\n",
      " 1   name          150346 non-null  object\n",
      " 2   address       150346 non-null  object\n",
      " 3   city          150346 non-null  object\n",
      " 4   state         150343 non-null  object\n",
      " 5   postal_code   150346 non-null  object\n",
      " 6   latitude      150346 non-null  object\n",
      " 7   longitude     150346 non-null  object\n",
      " 8   stars         150346 non-null  object\n",
      " 9   review_count  150346 non-null  object\n",
      " 10  is_open       150346 non-null  object\n",
      " 11  attributes    136602 non-null  object\n",
      " 12  categories    150243 non-null  object\n",
      " 13  hours         127123 non-null  object\n",
      " 14  business_id   5 non-null       object\n",
      " 15  name          5 non-null       object\n",
      " 16  address       5 non-null       object\n",
      " 17  city          5 non-null       object\n",
      " 18  state         5 non-null       object\n",
      " 19  postal_code   5 non-null       object\n",
      " 20  latitude      5 non-null       object\n",
      " 21  longitude     5 non-null       object\n",
      " 22  stars         5 non-null       object\n",
      " 23  review_count  5 non-null       object\n",
      " 24  is_open       5 non-null       object\n",
      " 25  attributes    5 non-null       object\n",
      " 26  categories    5 non-null       object\n",
      " 27  hours         5 non-null       object\n",
      "dtypes: object(28)\n",
      "memory usage: 33.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>...</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15195</th>\n",
       "      <td>u_0e1X9whtdIBURmiQCv_A</td>\n",
       "      <td>Burrito Boarder</td>\n",
       "      <td>17 3rd St N</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>TN</td>\n",
       "      <td>33701</td>\n",
       "      <td>27.771694</td>\n",
       "      <td>-82.636936</td>\n",
       "      <td>3.0</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99735</th>\n",
       "      <td>QTmwmIb8AHhyQBB2Q19xsg</td>\n",
       "      <td>Tommy's Express¬Æ Car Wash</td>\n",
       "      <td>1240 Missouri Ave N</td>\n",
       "      <td>Largo</td>\n",
       "      <td>DE</td>\n",
       "      <td>33770</td>\n",
       "      <td>27.928671</td>\n",
       "      <td>-82.78711</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id                       name              address  \\\n",
       "15195  u_0e1X9whtdIBURmiQCv_A            Burrito Boarder          17 3rd St N   \n",
       "99735  QTmwmIb8AHhyQBB2Q19xsg  Tommy's Express¬Æ Car Wash  1240 Missouri Ave N   \n",
       "\n",
       "                   city state postal_code   latitude  longitude stars  \\\n",
       "15195  Saint Petersburg    TN       33701  27.771694 -82.636936   3.0   \n",
       "99735             Largo    DE       33770  27.928671  -82.78711   3.5   \n",
       "\n",
       "      review_count  ... state postal_code latitude longitude stars  \\\n",
       "15195          190  ...   NaN         NaN      NaN       NaN   NaN   \n",
       "99735            7  ...   NaN         NaN      NaN       NaN   NaN   \n",
       "\n",
       "      review_count is_open attributes categories hours  \n",
       "15195          NaN     NaN        NaN        NaN   NaN  \n",
       "99735          NaN     NaN        NaN        NaN   NaN  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = pd.read_pickle('../0_Dataset/Yelp/business.pkl')\n",
    "business.info()\n",
    "business.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (150243, 14)\n",
      "         columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0    business_id      100.00     0.00            0    object\n",
      "1           name      100.00     0.00            0    object\n",
      "2        address      100.00     0.00            0    object\n",
      "3           city      100.00     0.00            0    object\n",
      "4          state      100.00     0.00            3    object\n",
      "5    postal_code      100.00     0.00            0    object\n",
      "6       latitude      100.00     0.00            0    object\n",
      "7      longitude      100.00     0.00            0    object\n",
      "8          stars      100.00     0.00            0    object\n",
      "9   review_count      100.00     0.00            0    object\n",
      "10       is_open      100.00     0.00            0    object\n",
      "11    attributes       90.92     9.08        13642    object\n",
      "12    categories      100.00     0.00            0    object\n",
      "13         hours       84.61    15.39        23120    object\n"
     ]
    }
   ],
   "source": [
    "data_type_check(business)\n",
    "business.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar en parquet\n",
    "business.to_parquet(\"../0_Dataset/Yelp/business.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos por porci√≥n\n",
    "chunk_s = 50000\n",
    "\n",
    "# Ruta del archivo\n",
    "archivo = '../0_Dataset/Yelp/review.json'\n",
    "\n",
    "# Inicializar una lista para almacenar las muestras\n",
    "muestras = []\n",
    "\n",
    "# Se carga el JSON en un DataFrame por partes y se toma una muestra de cada parte\n",
    "for df in pd.read_json(archivo, lines=True, chunksize=chunk_s):\n",
    "    muestra = df.sample(frac=0.03, random_state=1)  # Ajusta el tama√±o de la muestra seg√∫n tus necesidades\n",
    "    muestras.append(muestra)\n",
    "\n",
    "# Concatenar todas las muestras en un √∫nico DataFrame\n",
    "df_muestra_completa = pd.concat(muestras, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (209708, 9)\n",
      "       columna  %_no_nulos  %_nulos  total_nulos       tipo_dato\n",
      "0    review_id       100.0      0.0            0          object\n",
      "1      user_id       100.0      0.0            0          object\n",
      "2  business_id       100.0      0.0            0          object\n",
      "3        stars       100.0      0.0            0           int64\n",
      "4       useful       100.0      0.0            0           int64\n",
      "5        funny       100.0      0.0            0           int64\n",
      "6         cool       100.0      0.0            0           int64\n",
      "7         text       100.0      0.0            0          object\n",
      "8         date       100.0      0.0            0  datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_muestra_completa)\n",
    "df_muestra_completa.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üì§ LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la muestra en un archivo Parquet\n",
    "muestra_archivo = '../0_Dataset/Yelp/review_reducido.parquet'\n",
    "df_muestra_completa.to_parquet(muestra_archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkin.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del archivo Parquet reducido: 87.89 MB\n",
      "El archivo es menor de 90 MB. Podr√≠as aumentar la fracci√≥n.\n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo JSON\n",
    "checkin_path = '../0_Dataset/Yelp/checkin.json'\n",
    "output_path = '../0_Dataset/Yelp/checkin_reducido.parquet'\n",
    "\n",
    "# Leer JSON\n",
    "df = pd.read_json(checkin_path, lines=True)\n",
    "\n",
    "# Estimar la fracci√≥n de datos para que el archivo resultante pese menos de 100 MB\n",
    "# Aqu√≠ asumimos que podemos trabajar con el 10% de los datos originales.\n",
    "# Ajusta la fracci√≥n seg√∫n sea necesario despu√©s de verificar el tama√±o del archivo resultante.\n",
    "fraccion = 0.70\n",
    "\n",
    "# Tomar una muestra aleatoria del dataset\n",
    "df_muestra = df.sample(frac=fraccion, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_check(df_muestra)\n",
    "df_muestra.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üì§ LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar la muestra como un archivo Parquet\n",
    "pq.write_table(pa.Table.from_pandas(df_muestra), output_path)\n",
    "\n",
    "# Verificar el tama√±o del archivo resultante\n",
    "file_size = os.path.getsize(output_path) / (1024 * 1024)  # Convertir a MB\n",
    "print(f'Tama√±o del archivo Parquet reducido: {file_size:.2f} MB')\n",
    "\n",
    "# Ajustar la fracci√≥n si es necesario\n",
    "if file_size > 100:\n",
    "    print(\"El archivo sigue siendo demasiado grande. Reduce la fracci√≥n y vuelve a intentarlo.\")\n",
    "elif file_size < 90:\n",
    "    print(\"El archivo es menor de 90 MB. Podr√≠as aumentar la fracci√≥n.\")\n",
    "else:\n",
    "    print(\"El tama√±o del archivo es adecuado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tip.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo JSON\n",
    "tip = '../0_Dataset/Yelp/tip.json'\n",
    "\n",
    "# Leer el archivo JSON\n",
    "df_tip = pd.read_json(tip, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_check(df_tip)\n",
    "df_tip.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar en formato Parquet, cambiando el sufijo '.json' a '.parquet'\n",
    "df_tip.to_parquet(tip.replace('.json', '.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo Parquet original\n",
    "user_path = '../0_Dataset/Yelp/user.parquet'\n",
    "\n",
    "# Leer el archivo Parquet\n",
    "df = pd.read_parquet(user_path)\n",
    "\n",
    "# Obtener una muestra aleatoria del 3% del DataFrame (ajustar el tama√±o seg√∫n sea necesario)\n",
    "sample_df = df.sample(frac=0.03, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_check(sample_df)\n",
    "sample_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta del archivo Parquet de muestra\n",
    "sample_path = '../0_Dataset/Yelp/user_reducido.parquet'\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo Parquet\n",
    "sample_df.to_parquet(sample_path, index=False, compression='snappy')\n",
    "\n",
    "print(f\"Muestra guardada en {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Gogle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **üìÇProcesamiento del 1er archivo: `Google Maps/metadata-sitios/review-Florida-`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews Florida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ **Extraccion** de los datos y primera exploraci√≥n \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü Primero, vamos a convertir los datos de las rese√±as de Google Maps del estado de Florida, distribuidos en 11 archivos JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222749</th>\n",
       "      <td>1.158438e+20</td>\n",
       "      <td>Eliezer Maxime</td>\n",
       "      <td>1610445470638</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x88dd717495ae0a6d:0x1f7f551c2c6eccb1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824985</th>\n",
       "      <td>1.050261e+20</td>\n",
       "      <td>alejandro sanchez</td>\n",
       "      <td>1600115059710</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x88d9c04e0e2036eb:0xc3bd5480cbaf8787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id               name           time  rating  text  pics  \\\n",
       "222749   1.158438e+20     Eliezer Maxime  1610445470638       5  None  None   \n",
       "2824985  1.050261e+20  alejandro sanchez  1600115059710       4  None  None   \n",
       "\n",
       "         resp                                gmap_id  \n",
       "222749   None  0x88dd717495ae0a6d:0x1f7f551c2c6eccb1  \n",
       "2824985  None  0x88d9c04e0e2036eb:0xc3bd5480cbaf8787  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se especifica la ruta que contiene la carpeta con los archivos:\n",
    "carpeta = \"../0_Dataset/review-Florida\"\n",
    "\n",
    "# Se crea lista vac√≠a donde se almacenar√°n los dataframes de cada archivo:\n",
    "reviews = []\n",
    "\n",
    "# Se recorre por todos los archivos en la carpeta:\n",
    "for filename in os.listdir(carpeta):\n",
    "    if filename.endswith('.json'):\n",
    "        # Se carga el archivo JSON en un DataFrame de Pandas:\n",
    "        filepath = os.path.join(carpeta, filename)\n",
    "        df = pd.read_json(filepath, lines = True)\n",
    "        \n",
    "        # Se agrega el DataFrame a la lista:\n",
    "        reviews.append(df)\n",
    "\n",
    "# Se combinan todos los DataFrames en uno solo usando pd.concat:\n",
    "df_rev_FL = pd.concat(reviews, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (2850000, 8)\n",
      "   columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0  user_id      100.00     0.00            0   float64\n",
      "1     name      100.00     0.00            0    object\n",
      "2     time      100.00     0.00            0     int64\n",
      "3   rating      100.00     0.00            0     int64\n",
      "4     text       62.12    37.88      1079510    object\n",
      "5     pics        3.66    96.34      2745810    object\n",
      "6     resp       15.98    84.02      2394601    object\n",
      "7  gmap_id      100.00     0.00            0    object\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_rev_FL)\n",
    "df_rev_FL.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_FL_muestra = df_rev_FL.sample(frac=0.25, random_state=1) \n",
    "# Se exporta el archivo en formato parquet:\n",
    "df_rev_FL_muestra.to_parquet(\"../0_Dataset/Google/G_review_FL.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata-sitios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü La \"metadata\" incluye la informaci√≥n de diversos establecimientos en Google Maps.\n",
    "\n",
    "üìÇ Esta informaci√≥n est√° dividida en 11 archivos JSON, organizados en 3 carpetas para facilitar el procesamiento y almacenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la ruta que contiene la carpeta con los archivos:\n",
    "carpeta = \"../0_Dataset/Google/metadata-sitios\"\n",
    "\n",
    "# Se crea lista vac√≠a donde se almacenar√°n los dataframes de cada archivo:\n",
    "metadata = []\n",
    "\n",
    "# Se recorre por todos los archivos en la carpeta:\n",
    "for filename in os.listdir(carpeta):\n",
    "    if filename.endswith('.json'):\n",
    "        # Se carga el archivo JSON en un DataFrame de Pandas:\n",
    "        filepath = os.path.join(carpeta, filename)\n",
    "        df1 = pd.read_json(filepath, lines = True)\n",
    "        \n",
    "        # Se agrega el DataFrame a la lista:\n",
    "        metadata.append(df1)\n",
    "\n",
    "# Se combinan todos los DataFrames en uno solo usando pd.concat:\n",
    "df_rev_FL = pd.concat(metadata, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (2200008, 15)\n",
      "             columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0               name      100.00     0.00           30    object\n",
      "1            address       97.09     2.91        64075    object\n",
      "2            gmap_id      100.00     0.00            0    object\n",
      "3        description        7.20    92.80      2041504    object\n",
      "4           latitude      100.00     0.00            0   float64\n",
      "5          longitude      100.00     0.00            0   float64\n",
      "6           category       99.37     0.63        13824    object\n",
      "7         avg_rating      100.00     0.00            0   float64\n",
      "8     num_of_reviews      100.00     0.00            0     int64\n",
      "9              price        7.72    92.28      2030122    object\n",
      "10             hours       72.78    27.22       598803    object\n",
      "11              MISC       75.59    24.41       536945    object\n",
      "12             state       74.20    25.80       567655    object\n",
      "13  relative_results       89.55    10.45       229802    object\n",
      "14               url      100.00     0.00            0    object\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_rev_FL)\n",
    "df_rev_FL.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì§ LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660002, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev_FL_muestra = df_rev_FL.sample(frac=0.15, random_state=1) \n",
    "df_rev_FL_muestra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se exporta el archivo en formato parquet:\n",
    "df_rev_FL_muestra.to_parquet(\"../0_Dataset/Google/G_metadata_FL_reducido.parquet\", engine=\"pyarrow\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Posibles soluciones: Exportar multiples parquet de metadata y unirlos luego \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
