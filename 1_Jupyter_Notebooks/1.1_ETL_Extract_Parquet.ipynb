{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **ETL (Extract, Transform, Load)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ipynb vamos a Extraer los archivos y cargarlos en parquet. Luego en otro archivo haremos las transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien vamos a estar utilizando la funcion personalizada personalizada `data_type_check` invocada desde `data_utils.py` para dejar un vistazo r√°pido del dataframe y  poder observar:\n",
    "- Variables categ√≥ricas\n",
    "- Variables num√©ricas\n",
    "- Dimensiones del dataframe\n",
    "- Nulos\n",
    "- Tipos de datos\n",
    "- Informacion acerca de los datos faltantes o nulos de cada columna    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Importamos las librer√≠as que vamos a usar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from data_utils import data_type_check\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### business.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150346 entries, 0 to 150345\n",
      "Data columns (total 28 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   business_id   150346 non-null  object\n",
      " 1   name          150346 non-null  object\n",
      " 2   address       150346 non-null  object\n",
      " 3   city          150346 non-null  object\n",
      " 4   state         150343 non-null  object\n",
      " 5   postal_code   150346 non-null  object\n",
      " 6   latitude      150346 non-null  object\n",
      " 7   longitude     150346 non-null  object\n",
      " 8   stars         150346 non-null  object\n",
      " 9   review_count  150346 non-null  object\n",
      " 10  is_open       150346 non-null  object\n",
      " 11  attributes    136602 non-null  object\n",
      " 12  categories    150243 non-null  object\n",
      " 13  hours         127123 non-null  object\n",
      " 14  business_id   5 non-null       object\n",
      " 15  name          5 non-null       object\n",
      " 16  address       5 non-null       object\n",
      " 17  city          5 non-null       object\n",
      " 18  state         5 non-null       object\n",
      " 19  postal_code   5 non-null       object\n",
      " 20  latitude      5 non-null       object\n",
      " 21  longitude     5 non-null       object\n",
      " 22  stars         5 non-null       object\n",
      " 23  review_count  5 non-null       object\n",
      " 24  is_open       5 non-null       object\n",
      " 25  attributes    5 non-null       object\n",
      " 26  categories    5 non-null       object\n",
      " 27  hours         5 non-null       object\n",
      "dtypes: object(28)\n",
      "memory usage: 33.3+ MB\n"
     ]
    }
   ],
   "source": [
    "business = pd.read_pickle('../0_Dataset/Data_Sucia/business.pkl') #'../0_Dataset/Data_Sucia/Yelp/business.pkl'\n",
    "business.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos columnas duplicadas, procedemos a quitarlas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150346 entries, 0 to 150345\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   business_id   150346 non-null  object\n",
      " 1   name          150346 non-null  object\n",
      " 2   address       150346 non-null  object\n",
      " 3   city          150346 non-null  object\n",
      " 4   state         150343 non-null  object\n",
      " 5   postal_code   150346 non-null  object\n",
      " 6   latitude      150346 non-null  object\n",
      " 7   longitude     150346 non-null  object\n",
      " 8   stars         150346 non-null  object\n",
      " 9   review_count  150346 non-null  object\n",
      " 10  is_open       150346 non-null  object\n",
      " 11  attributes    136602 non-null  object\n",
      " 12  categories    150243 non-null  object\n",
      " 13  hours         127123 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 17.2+ MB\n"
     ]
    }
   ],
   "source": [
    "business = business.loc[:, ~business.columns.duplicated()]\n",
    "business.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos los nulos y duplicados de categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes: Cantidad de duplicados en 'categories': 67185\n",
      "Antes: Cantidad de NaNs en 'categories': 103\n",
      "Despu√©s: Cantidad de NaNs en 'categories'  0\n",
      "Despu√©s: Cantidad de duplicados en 'categories' 67083\n"
     ]
    }
   ],
   "source": [
    "# Cuenta los duplicados y nulos en la columna 'categories' antes de cualquier eliminaci√≥n\n",
    "duplicados_inicial = business['categories'].duplicated().sum()\n",
    "nulos_inicial = business['categories'].isna().sum()\n",
    "\n",
    "print(\"Antes: Cantidad de duplicados en 'categories':\", duplicados_inicial)\n",
    "print(\"Antes: Cantidad de NaNs en 'categories':\", nulos_inicial)\n",
    "\n",
    "# Elimina las filas con valores NaN en la columna 'categories'\n",
    "business = business.dropna(subset=['categories'])\n",
    "\n",
    "# Cuenta los duplicados y nulos en la columna 'categories' despu√©s de eliminar NaNs\n",
    "duplicados_despues_nulos = business['categories'].duplicated().sum()\n",
    "nulos_despues_nulos = business['categories'].isna().sum()\n",
    "\n",
    "print(\"Despu√©s: Cantidad de NaNs en 'categories' \", nulos_despues_nulos)\n",
    "\n",
    "\n",
    "'''\n",
    "________________________________________________________________\n",
    "FUTURO: Descomentar o borrar\n",
    "Elimina las filas duplicadas basadas en la columna 'categories'\n",
    "business = business.drop_duplicates(subset=['categories'])  \n",
    "_________________________________________________________________  \n",
    "'''\n",
    "\n",
    "# Cuenta los duplicados en la columna 'categories' despu√©s de eliminar duplicados\n",
    "duplicados_final = business['categories'].duplicated().sum()\n",
    "\n",
    "print(\"Despu√©s: Cantidad de duplicados en 'categories'\", duplicados_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar en parquet\n",
    "business.to_parquet(\"../0_Dataset/Data_Sucia/Yelp/business.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos por porci√≥n\n",
    "chunk_s = 50000\n",
    "\n",
    "# Ruta del archivo\n",
    "archivo = '../0_Dataset/Yelp/review.json'\n",
    "\n",
    "# Inicializar una lista para almacenar las muestras\n",
    "muestras = []\n",
    "\n",
    "# Se carga el JSON en un DataFrame por partes y se toma una muestra de cada parte\n",
    "for df in pd.read_json(archivo, lines=True, chunksize=chunk_s):\n",
    "    muestra = df.sample(frac=0.03, random_state=1)  # Ajusta el tama√±o de la muestra seg√∫n tus necesidades\n",
    "    muestras.append(muestra)\n",
    "\n",
    "# Concatenar todas las muestras en un √∫nico DataFrame\n",
    "df_muestra_completa = pd.concat(muestras, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (209708, 9)\n",
      "       columna  %_no_nulos  %_nulos  total_nulos       tipo_dato\n",
      "0    review_id       100.0      0.0            0          object\n",
      "1      user_id       100.0      0.0            0          object\n",
      "2  business_id       100.0      0.0            0          object\n",
      "3        stars       100.0      0.0            0           int64\n",
      "4       useful       100.0      0.0            0           int64\n",
      "5        funny       100.0      0.0            0           int64\n",
      "6         cool       100.0      0.0            0           int64\n",
      "7         text       100.0      0.0            0          object\n",
      "8         date       100.0      0.0            0  datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82716</th>\n",
       "      <td>g_HGbCH5hLtP0wV14D0aVw</td>\n",
       "      <td>dv4qZSuKlUL4YuVQ6i4vCQ</td>\n",
       "      <td>mnN5N-DoS3uAcG5hVHKRBQ</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I generally only come to Michael's with my fia...</td>\n",
       "      <td>2021-05-13 15:11:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88987</th>\n",
       "      <td>7A_w9_VjxqLQT-DTFBPddQ</td>\n",
       "      <td>MKt2J_lRy8F8mHwBIyY_KQ</td>\n",
       "      <td>2KHS8Vuao5QZhs2YUE3b5g</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One star is too generous. I went in to get my ...</td>\n",
       "      <td>2016-06-04 19:08:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    review_id                 user_id             business_id  \\\n",
       "82716  g_HGbCH5hLtP0wV14D0aVw  dv4qZSuKlUL4YuVQ6i4vCQ  mnN5N-DoS3uAcG5hVHKRBQ   \n",
       "88987  7A_w9_VjxqLQT-DTFBPddQ  MKt2J_lRy8F8mHwBIyY_KQ  2KHS8Vuao5QZhs2YUE3b5g   \n",
       "\n",
       "       stars  useful  funny  cool  \\\n",
       "82716      3       3      1     0   \n",
       "88987      1       0      0     0   \n",
       "\n",
       "                                                    text                date  \n",
       "82716  I generally only come to Michael's with my fia... 2021-05-13 15:11:16  \n",
       "88987  One star is too generous. I went in to get my ... 2016-06-04 19:08:11  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_check(df_muestra_completa)\n",
    "df_muestra_completa.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üì§ LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la muestra en un archivo Parquet\n",
    "muestra_archivo = '../0_Dataset/Data_Sucia/Yelp/review_reducido.parquet'\n",
    "df_muestra_completa.to_parquet(muestra_archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkin.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo JSON\n",
    "checkin_path = '../0_Dataset/Yelp/checkin.json'\n",
    "output_path = '../0_Dataset/Yelp/Data_Sucia/checkin_reducido.parquet'\n",
    "\n",
    "# Leer JSON\n",
    "df = pd.read_json(checkin_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar la fracci√≥n de datos para que el archivo resultante pese menos de 100 MB\n",
    "# Aqu√≠ asumimos que podemos trabajar con el 10% de los datos originales.\n",
    "# Ajusta la fracci√≥n seg√∫n sea necesario despu√©s de verificar el tama√±o del archivo resultante.\n",
    "fraccion = 0.70\n",
    "\n",
    "# Tomar una muestra aleatoria del dataset\n",
    "df_muestra = df.sample(frac=fraccion, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (92351, 2)\n",
      "       columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0  business_id       100.0      0.0            0    object\n",
      "1         date       100.0      0.0            0    object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12361</th>\n",
       "      <td>4x6XkcuyzFHjlV7I7wqF0w</td>\n",
       "      <td>2012-02-22 01:47:21, 2012-04-27 13:28:41, 2012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101577</th>\n",
       "      <td>lNbllJ2epwcSIqaAUEXrxw</td>\n",
       "      <td>2018-03-19 19:35:38, 2019-04-15 12:02:59, 2019...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "12361   4x6XkcuyzFHjlV7I7wqF0w   \n",
       "101577  lNbllJ2epwcSIqaAUEXrxw   \n",
       "\n",
       "                                                     date  \n",
       "12361   2012-02-22 01:47:21, 2012-04-27 13:28:41, 2012...  \n",
       "101577  2018-03-19 19:35:38, 2019-04-15 12:02:59, 2019...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_check(df_muestra)\n",
    "df_muestra.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üì§ LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del archivo Parquet reducido: 87.89 MB\n",
      "El archivo es menor de 90 MB. Podr√≠as aumentar la fracci√≥n.\n"
     ]
    }
   ],
   "source": [
    "# Guardar la muestra como un archivo Parquet\n",
    "pq.write_table(pa.Table.from_pandas(df_muestra), output_path)\n",
    "\n",
    "# Verificar el tama√±o del archivo resultante\n",
    "file_size = os.path.getsize(output_path) / (1024 * 1024)  # Convertir a MB\n",
    "print(f'Tama√±o del archivo Parquet reducido: {file_size:.2f} MB')\n",
    "\n",
    "# Ajustar la fracci√≥n si es necesario\n",
    "if file_size > 100:\n",
    "    print(\"El archivo sigue siendo demasiado grande. Reduce la fracci√≥n y vuelve a intentarlo.\")\n",
    "elif file_size < 90:\n",
    "    print(\"El archivo es menor de 90 MB. Podr√≠as aumentar la fracci√≥n.\")\n",
    "else:\n",
    "    print(\"El tama√±o del archivo es adecuado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tip.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo JSON\n",
    "tip = '../0_Dataset/Data_Sucia/Yelp/tip.json'\n",
    "\n",
    "# Leer el archivo JSON\n",
    "df_tip = pd.read_json(tip, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (908915, 5)\n",
      "            columna  %_no_nulos  %_nulos  total_nulos       tipo_dato\n",
      "0           user_id       100.0      0.0            0          object\n",
      "1       business_id       100.0      0.0            0          object\n",
      "2              text       100.0      0.0            0          object\n",
      "3              date       100.0      0.0            0  datetime64[ns]\n",
      "4  compliment_count       100.0      0.0            0           int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>compliment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>894708</th>\n",
       "      <td>ZE09zaiVZnVz-P245EOHkw</td>\n",
       "      <td>uEWsfftrJ7ukPv1xyMVcrg</td>\n",
       "      <td>Extremely high priced. Not coming back.</td>\n",
       "      <td>2014-07-06 02:30:56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740005</th>\n",
       "      <td>1JqUn89C8NvMyLZtRv8prw</td>\n",
       "      <td>1FURjeGJi_LBXcJQg8eskw</td>\n",
       "      <td>Their Hawaiian burger is great it's by the bea...</td>\n",
       "      <td>2021-12-08 05:13:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id             business_id  \\\n",
       "894708  ZE09zaiVZnVz-P245EOHkw  uEWsfftrJ7ukPv1xyMVcrg   \n",
       "740005  1JqUn89C8NvMyLZtRv8prw  1FURjeGJi_LBXcJQg8eskw   \n",
       "\n",
       "                                                     text                date  \\\n",
       "894708            Extremely high priced. Not coming back. 2014-07-06 02:30:56   \n",
       "740005  Their Hawaiian burger is great it's by the bea... 2021-12-08 05:13:19   \n",
       "\n",
       "        compliment_count  \n",
       "894708                 0  \n",
       "740005                 0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_check(df_tip)\n",
    "df_tip.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar en formato Parquet, cambiando el sufijo '.json' a '.parquet'\n",
    "df_tip.to_parquet(tip.replace('.json', '.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo Parquet original\n",
    "user_path = '../0_Dataset/Yelp/user.parquet'\n",
    "\n",
    "# Leer el archivo Parquet\n",
    "df = pd.read_parquet(user_path)\n",
    "\n",
    "# Obtener una muestra aleatoria del 3% del DataFrame (ajustar el tama√±o seg√∫n sea necesario)\n",
    "sample_df = df.sample(frac=0.03, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (63168, 22)\n",
      "               columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0              user_id       100.0      0.0            0    object\n",
      "1                 name       100.0      0.0            0    object\n",
      "2         review_count       100.0      0.0            0     int64\n",
      "3        yelping_since       100.0      0.0            0    object\n",
      "4               useful       100.0      0.0            0     int64\n",
      "5                funny       100.0      0.0            0     int64\n",
      "6                 cool       100.0      0.0            0     int64\n",
      "7                elite       100.0      0.0            0    object\n",
      "8              friends       100.0      0.0            0    object\n",
      "9                 fans       100.0      0.0            0     int64\n",
      "10       average_stars       100.0      0.0            0   float64\n",
      "11      compliment_hot       100.0      0.0            0     int64\n",
      "12     compliment_more       100.0      0.0            0     int64\n",
      "13  compliment_profile       100.0      0.0            0     int64\n",
      "14     compliment_cute       100.0      0.0            0     int64\n",
      "15     compliment_list       100.0      0.0            0     int64\n",
      "16     compliment_note       100.0      0.0            0     int64\n",
      "17    compliment_plain       100.0      0.0            0     int64\n",
      "18     compliment_cool       100.0      0.0            0     int64\n",
      "19    compliment_funny       100.0      0.0            0     int64\n",
      "20   compliment_writer       100.0      0.0            0     int64\n",
      "21   compliment_photos       100.0      0.0            0     int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>friends</th>\n",
       "      <th>fans</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233812</th>\n",
       "      <td>tvCILc8B7_noSUKkIsze_Q</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>284</td>\n",
       "      <td>2013-03-27 15:55:54</td>\n",
       "      <td>1138</td>\n",
       "      <td>298</td>\n",
       "      <td>776</td>\n",
       "      <td>2017,2018,2019,20,20</td>\n",
       "      <td>bwj4gvnEeDrH0LWexKIgpQ, GJKVc86sHbx27PUYkV88wg...</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358876</th>\n",
       "      <td>144I0K9Dnn1y96wNiMR_2w</td>\n",
       "      <td>gregory</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-07-29 08:45:40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id     name  review_count        yelping_since  \\\n",
       "233812  tvCILc8B7_noSUKkIsze_Q  Mallory           284  2013-03-27 15:55:54   \n",
       "358876  144I0K9Dnn1y96wNiMR_2w  gregory             5  2021-07-29 08:45:40   \n",
       "\n",
       "        useful  funny  cool                 elite  \\\n",
       "233812    1138    298   776  2017,2018,2019,20,20   \n",
       "358876       1      0     1                         \n",
       "\n",
       "                                                  friends  fans  ...  \\\n",
       "233812  bwj4gvnEeDrH0LWexKIgpQ, GJKVc86sHbx27PUYkV88wg...    58  ...   \n",
       "358876                                               None     0  ...   \n",
       "\n",
       "        compliment_more  compliment_profile  compliment_cute  compliment_list  \\\n",
       "233812                2                   0                0                1   \n",
       "358876                0                   0                0                0   \n",
       "\n",
       "        compliment_note  compliment_plain  compliment_cool  compliment_funny  \\\n",
       "233812               18                22               38                38   \n",
       "358876                0                 0                0                 0   \n",
       "\n",
       "        compliment_writer  compliment_photos  \n",
       "233812                 22                 13  \n",
       "358876                  0                  0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_check(sample_df)\n",
    "sample_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra guardada en ../0_Dataset/Yelp/user_reducido.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ruta del archivo Parquet de muestra\n",
    "sample_path = '../0_Dataset/Yelp/user_reducido.parquet'\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo Parquet\n",
    "sample_df.to_parquet(sample_path, index=False, compression='snappy')\n",
    "\n",
    "print(f\"Muestra guardada en {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Gogle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **üìÇProcesamiento del 1er archivo: `Google Maps/metadata-sitios/review-Florida-`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews Florida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ **Extraccion** de los datos y primera exploraci√≥n \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü Primero, vamos a convertir los datos de las rese√±as de Google Maps del estado de Florida, distribuidos en 11 archivos JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la ruta que contiene la carpeta con los archivos:\n",
    "carpeta = \"../0_Dataset/review-Florida\"\n",
    "\n",
    "# Se crea lista vac√≠a donde se almacenar√°n los dataframes de cada archivo:\n",
    "reviews = []\n",
    "\n",
    "# Se recorre por todos los archivos en la carpeta:\n",
    "for filename in os.listdir(carpeta):\n",
    "    if filename.endswith('.json'):\n",
    "        # Se carga el archivo JSON en un DataFrame de Pandas:\n",
    "        filepath = os.path.join(carpeta, filename)\n",
    "        df = pd.read_json(filepath, lines = True)\n",
    "        \n",
    "        # Se agrega el DataFrame a la lista:\n",
    "        reviews.append(df)\n",
    "\n",
    "# Se combinan todos los DataFrames en uno solo usando pd.concat:\n",
    "df_rev_FL = pd.concat(reviews, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (2850000, 8)\n",
      "   columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0  user_id      100.00     0.00            0   float64\n",
      "1     name      100.00     0.00            0    object\n",
      "2     time      100.00     0.00            0     int64\n",
      "3   rating      100.00     0.00            0     int64\n",
      "4     text       62.12    37.88      1079510    object\n",
      "5     pics        3.66    96.34      2745810    object\n",
      "6     resp       15.98    84.02      2394601    object\n",
      "7  gmap_id      100.00     0.00            0    object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071965</th>\n",
       "      <td>1.032315e+20</td>\n",
       "      <td>Yunier Velazquez</td>\n",
       "      <td>1580228259725</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x88c2efd165f1e9e5:0x37f1f8c780f4963f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294965</th>\n",
       "      <td>1.076242e+20</td>\n",
       "      <td>Gretchen Booth</td>\n",
       "      <td>1554850678093</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x88e5b9ab392ece73:0x1f8770a56f649da0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id              name           time  rating  text  pics  \\\n",
       "1071965  1.032315e+20  Yunier Velazquez  1580228259725       5  None  None   \n",
       "294965   1.076242e+20    Gretchen Booth  1554850678093       5  None  None   \n",
       "\n",
       "         resp                                gmap_id  \n",
       "1071965  None  0x88c2efd165f1e9e5:0x37f1f8c780f4963f  \n",
       "294965   None  0x88e5b9ab392ece73:0x1f8770a56f649da0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_check(df_rev_FL)\n",
    "df_rev_FL.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_FL_muestra = df_rev_FL.sample(frac=0.25, random_state=1) \n",
    "# Se exporta el archivo en formato parquet:\n",
    "df_rev_FL_muestra.to_parquet(\"../0_Dataset/Data_Sucia/Google/G_review_FL_reducido.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata-sitios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü La \"metadata\" incluye la informaci√≥n de diversos establecimientos en Google Maps.\n",
    "\n",
    "üìÇ Esta informaci√≥n est√° dividida en 11 archivos JSON, organizados en 3 carpetas para facilitar el procesamiento y almacenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la ruta que contiene la carpeta con los archivos:\n",
    "carpeta = \"../0_Dataset/Data_Sucia/Google/metadata-sitios\"\n",
    "\n",
    "# Se crea lista vac√≠a donde se almacenar√°n los dataframes de cada archivo:\n",
    "metadata = []\n",
    "\n",
    "# Se recorre por todos los archivos en la carpeta:\n",
    "for filename in os.listdir(carpeta):\n",
    "    if filename.endswith('.json'):\n",
    "        # Se carga el archivo JSON en un DataFrame de Pandas:\n",
    "        filepath = os.path.join(carpeta, filename)\n",
    "        df1 = pd.read_json(filepath, lines = True)\n",
    "        \n",
    "        # Se agrega el DataFrame a la lista:\n",
    "        metadata.append(df1)\n",
    "\n",
    "# Se combinan todos los DataFrames en uno solo usando pd.concat:\n",
    "df_rev_FL = pd.concat(metadata, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (2200008, 15)\n",
      "             columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0               name      100.00     0.00           30    object\n",
      "1            address       97.09     2.91        64075    object\n",
      "2            gmap_id      100.00     0.00            0    object\n",
      "3        description        7.20    92.80      2041504    object\n",
      "4           latitude      100.00     0.00            0   float64\n",
      "5          longitude      100.00     0.00            0   float64\n",
      "6           category       99.37     0.63        13824    object\n",
      "7         avg_rating      100.00     0.00            0   float64\n",
      "8     num_of_reviews      100.00     0.00            0     int64\n",
      "9              price        7.72    92.28      2030122    object\n",
      "10             hours       72.78    27.22       598803    object\n",
      "11              MISC       75.59    24.41       536945    object\n",
      "12             state       74.20    25.80       567655    object\n",
      "13  relative_results       89.55    10.45       229802    object\n",
      "14               url      100.00     0.00            0    object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>hours</th>\n",
       "      <th>MISC</th>\n",
       "      <th>state</th>\n",
       "      <th>relative_results</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414902</th>\n",
       "      <td>Ralph's Barber Shop</td>\n",
       "      <td>Ralph's Barber Shop, 1827-A, Reynolds Ave, Nor...</td>\n",
       "      <td>0x88fe65e4c7dd302f:0x97afae4dd6103404</td>\n",
       "      <td>None</td>\n",
       "      <td>32.858370</td>\n",
       "      <td>-79.969606</td>\n",
       "      <td>[Barber shop]</td>\n",
       "      <td>4.9</td>\n",
       "      <td>28</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Tuesday, 10AM‚Äì6PM], [Wednesday, 10AM‚Äì6PM], [...</td>\n",
       "      <td>{'Highlights': ['LGBTQ friendly'], 'Accessibil...</td>\n",
       "      <td>Open ‚ãÖ Closes 6PM</td>\n",
       "      <td>[0x88fe64e8907df079:0x82bc492c4ace3924, 0x88fe...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174132</th>\n",
       "      <td>Eyeworks At Midtown</td>\n",
       "      <td>Eyeworks At Midtown, 316 Gray St, Houston, TX ...</td>\n",
       "      <td>0x8640bf41a157d6cd:0xc10fff1ee4d69980</td>\n",
       "      <td>None</td>\n",
       "      <td>29.751944</td>\n",
       "      <td>-95.377058</td>\n",
       "      <td>[Eye care center, Optometrist]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>[[Thursday, 10AM‚Äì5PM], [Friday, Closed], [Satu...</td>\n",
       "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
       "      <td>Closed ‚ãÖ Opens 10AM</td>\n",
       "      <td>[0x8640bf6d03eca757:0x19ac5705011d7bf0, 0x8640...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  \\\n",
       "414902   Ralph's Barber Shop   \n",
       "1174132  Eyeworks At Midtown   \n",
       "\n",
       "                                                   address  \\\n",
       "414902   Ralph's Barber Shop, 1827-A, Reynolds Ave, Nor...   \n",
       "1174132  Eyeworks At Midtown, 316 Gray St, Houston, TX ...   \n",
       "\n",
       "                                       gmap_id description   latitude  \\\n",
       "414902   0x88fe65e4c7dd302f:0x97afae4dd6103404        None  32.858370   \n",
       "1174132  0x8640bf41a157d6cd:0xc10fff1ee4d69980        None  29.751944   \n",
       "\n",
       "         longitude                        category  avg_rating  \\\n",
       "414902  -79.969606                   [Barber shop]         4.9   \n",
       "1174132 -95.377058  [Eye care center, Optometrist]         4.6   \n",
       "\n",
       "         num_of_reviews price  \\\n",
       "414902               28  None   \n",
       "1174132               8  None   \n",
       "\n",
       "                                                     hours  \\\n",
       "414902   [[Tuesday, 10AM‚Äì6PM], [Wednesday, 10AM‚Äì6PM], [...   \n",
       "1174132  [[Thursday, 10AM‚Äì5PM], [Friday, Closed], [Satu...   \n",
       "\n",
       "                                                      MISC  \\\n",
       "414902   {'Highlights': ['LGBTQ friendly'], 'Accessibil...   \n",
       "1174132  {'Accessibility': ['Wheelchair accessible entr...   \n",
       "\n",
       "                       state  \\\n",
       "414902     Open ‚ãÖ Closes 6PM   \n",
       "1174132  Closed ‚ãÖ Opens 10AM   \n",
       "\n",
       "                                          relative_results  \\\n",
       "414902   [0x88fe64e8907df079:0x82bc492c4ace3924, 0x88fe...   \n",
       "1174132  [0x8640bf6d03eca757:0x19ac5705011d7bf0, 0x8640...   \n",
       "\n",
       "                                                       url  \n",
       "414902   https://www.google.com/maps/place//data=!4m2!3...  \n",
       "1174132  https://www.google.com/maps/place//data=!4m2!3...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_check(df_rev_FL)\n",
    "df_rev_FL.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì§ LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_FL_muestra = df_rev_FL.sample(frac=0.10, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se exporta el archivo en formato parquet:\n",
    "df_rev_FL_muestra.to_parquet(\"../0_Dataset/Data_Sucia/Google/G_metadata_FL_reducido.parquet\", engine=\"pyarrow\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Posibles soluciones: Exportar multiples parquet de metadata y unirlos luego "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
