{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **ETL (Extract, Transform, Load)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üìÇProcesamiento del 1er archivo: `Google Maps/metadata-sitios/review-hawaii-`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Importamos las librer√≠as que vamos a usar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import data_utils   \n",
    "from data_utils import data_type_check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews Hawaii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ **Extraccion** de los datos y primera exploraci√≥n \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü Primero, vamos a convertir los datos de las rese√±as de Google Maps del estado de Hawaii, distribuidos en 11 archivos JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402458</th>\n",
       "      <td>1.061036e+20</td>\n",
       "      <td>Steve Leith</td>\n",
       "      <td>1618783273967</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x7c006e6de49e8a1f:0xa44b7af81f555ead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259332</th>\n",
       "      <td>1.035604e+20</td>\n",
       "      <td>Nathan Gold</td>\n",
       "      <td>1453692250037</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x7c0058d3c82ca71d:0xcc193f36c9ed743d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id         name           time  rating  text  pics  resp  \\\n",
       "402458   1.061036e+20  Steve Leith  1618783273967       5  None  None  None   \n",
       "1259332  1.035604e+20  Nathan Gold  1453692250037       5  None  None  None   \n",
       "\n",
       "                                       gmap_id  \n",
       "402458   0x7c006e6de49e8a1f:0xa44b7af81f555ead  \n",
       "1259332  0x7c0058d3c82ca71d:0xcc193f36c9ed743d  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se especifica la ruta que contiene la carpeta con los archivos:\n",
    "carpeta = \"../0_Dataset/review-Hawaii\"\n",
    "\n",
    "# Se crea lista vac√≠a donde se almacenar√°n los dataframes de cada archivo:\n",
    "reviews = []\n",
    "\n",
    "# Se recorre por todos los archivos en la carpeta:\n",
    "for filename in os.listdir(carpeta):\n",
    "    if filename.endswith('.json'):\n",
    "        # Se carga el archivo JSON en un DataFrame de Pandas:\n",
    "        filepath = os.path.join(carpeta, filename)\n",
    "        df = pd.read_json(filepath, lines = True)\n",
    "        \n",
    "        # Se agrega el DataFrame a la lista:\n",
    "        reviews.append(df)\n",
    "\n",
    "# Se combinan todos los DataFrames en uno solo usando pd.concat:\n",
    "df_rev_hawai = pd.concat(reviews, ignore_index=True)\n",
    "\n",
    "# Se chequean 2 valores:\n",
    "df_rev_hawai.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la funcion personalizada `data_type_check` invocada desde `data_utils.py` podemos observar:\n",
    "- Variables categ√≥ricas\n",
    "- Variables num√©ricas\n",
    "- Dimensiones del dataframe\n",
    "- Nulos\n",
    "- Tipos de datos\n",
    "- Informacion acerca de los datos faltantes o nulos de cada columna    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (1504347, 8)\n",
      "   columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0  user_id      100.00     0.00            0   float64\n",
      "1     name      100.00     0.00            0    object\n",
      "2     time      100.00     0.00            0     int64\n",
      "3   rating      100.00     0.00            0     int64\n",
      "4     text       56.68    43.32       651751    object\n",
      "5     pics        8.82    91.18      1371645    object\n",
      "6     resp        7.23    92.77      1395548    object\n",
      "7  gmap_id      100.00     0.00            0    object\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_rev_hawai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido el parquet en 2 muestras \n",
    "df_rev_hawai_muestra = df_rev_hawai[:int(len(df_rev_hawai)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se exporta el archivo en formato parquet:\n",
    "df_rev_hawai_muestra.to_parquet(\"../0_Dataset/Google_reviews_california_muestra.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0x7c00159b5b1b1d25:0x8d2d85d4a758290e',\n",
       "       '0x7c006de89f2d86e1:0x23d998532e9317a6',\n",
       "       '0x7c0065ffde090f89:0x910053daf03f6f3f', ...,\n",
       "       '0x7c006df045a36271:0x2e82a95b7fa088b4',\n",
       "       '0x7c001226c044ba33:0xec80ba7ae569fed',\n",
       "       '0x7c006d9f6a3fffff:0x93e62ce20799a22d'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se buscan los valores √∫nicos en gmap_id:\n",
    "df_rev_hawai_muestra = df_rev_hawai_muestra.dropna(subset=\"gmap_id\")\n",
    "id_unicos = df_rev_hawai_muestra[\"gmap_id\"].unique()\n",
    "id_unicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata-sitios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü La \"metadata\" incluye la informaci√≥n de diversos establecimientos en Google Maps.\n",
    "\n",
    "üìÇ Esta informaci√≥n est√° dividida en 11 archivos JSON, organizados en 3 carpetas para facilitar el procesamiento y almacenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la ruta que contiene la carpeta con los archivos:\n",
    "carpeta = \"../0_Dataset/metadata-sitios\"\n",
    "\n",
    "# Se crea lista vac√≠a donde se almacenar√°n los dataframes de cada archivo:\n",
    "metadata = []\n",
    "\n",
    "# Se recorre por todos los archivos en la carpeta:\n",
    "for filename in os.listdir(carpeta):\n",
    "    if filename.endswith('.json'):\n",
    "        # Se carga el archivo JSON en un DataFrame de Pandas:\n",
    "        filepath = os.path.join(carpeta, filename)\n",
    "        df1 = pd.read_json(filepath, lines = True)\n",
    "        \n",
    "        # Se agrega el DataFrame a la lista:\n",
    "        metadata.append(df1)\n",
    "\n",
    "# Se combinan todos los DataFrames en uno solo usando pd.concat:\n",
    "df_md_hawaii = pd.concat(metadata, ignore_index=True)\n",
    "\n",
    "# Se chequean 2 valores:\n",
    "df_md_hawaii.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la funcion personalizada `data_type_check` invocada desde `data_utils.py` podemos observar:\n",
    "- Variables categ√≥ricas\n",
    "- Variables num√©ricas\n",
    "- Dimensiones del dataframe\n",
    "- Nulos\n",
    "- Tipos de datos\n",
    "- Informacion acerca de los datos faltantes o nulos de cada columna    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " Resumen del dataframe:\n",
      "\n",
      "========================================\n",
      "Dimensiones:  (2475009, 15)\n",
      "             columna  %_no_nulos  %_nulos  total_nulos tipo_dato\n",
      "0               name      100.00     0.00           33    object\n",
      "1            address       97.19     2.81        69648    object\n",
      "2            gmap_id      100.00     0.00            0    object\n",
      "3        description        7.53    92.47      2288605    object\n",
      "4           latitude      100.00     0.00            0   float64\n",
      "5          longitude      100.00     0.00            0   float64\n",
      "6           category       99.39     0.61        15163    object\n",
      "7         avg_rating      100.00     0.00            0   float64\n",
      "8     num_of_reviews      100.00     0.00            0     int64\n",
      "9              price        8.12    91.88      2273984    object\n",
      "10             hours       73.19    26.81       663517    object\n",
      "11              MISC       76.15    23.85       590243    object\n",
      "12             state       74.56    25.44       629696    object\n",
      "13  relative_results       89.88    10.12       250397    object\n",
      "14               url      100.00     0.00            0    object\n"
     ]
    }
   ],
   "source": [
    "data_type_check(df_md_hawaii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üîÑ TRANSFORM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Limpieza pendiente, es posible que lo hagamos en la nube y ya.\n",
    "- Falta duplicados\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üì§ LOAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido el parquet en 2 muestras para poder subirlo a github y mostralo al equipo\n",
    "df_md_hawaii_muestra = df_md_hawaii[:int(len(df_md_hawaii)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se exporta el archivo en formato parquet:\n",
    "df_md_hawaii_muestra.to_parquet(\"../0_Dataset/Google_metadata_california_muestra.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Posibles soluciones: Exportar multiples parquet de metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
