# Proyecto YELP & GOOGLE MAPS - REVIEWS AND RECOMMENDATIONS

![1718594640848](image/README/1718594640848.png)

## √çndice del Proyecto

1. [Objetivo y Alcance del Proyecto](#objetivo-y-alcance-del-proyecto)
2. [Descripci√≥n del Conjunto de Datos](#descripci√≥n-del-conjunto-de-datos)
3. [Plan de Trabajo](#plan-de-trabajo)
4. [Stack Tecnol√≥gico](#stack-tecnol√≥gico)
5. [Sprints](#sprints)
   - [Sprint 1: Puesta en marcha del proyecto y Trabajo con Datos](#sprint-1-puesta-en-marcha-del-proyecto-y-trabajo-con-datos)
   - [Sprint 2: Data Engineering](#sprint-2-data-engineering)
   - [Sprint 3: Data Analytics + ML](#sprint-3-data-analytics--ml)
6. [Pipeline del Proceso ETL](#pipeline-del-proceso-etl)
7. [An√°lisis de los Datos](#an√°lisis-de-los-datos)
8. [Tecnolog√≠as Utilizadas](#tecnolog√≠as-utilizadas)
9. [√çndice de Archivos del Repositorio](#√≠ndice-de-archivos-del-repositorio)
10. [Equipo Involucrado](#equipo-involucrado)

## Objetivo y Alcance del Proyecto

El objetivo de este proyecto es analizar y recomendar establecimientos basados en las rese√±as y datos obtenidos de Yelp y Google Maps. Este an√°lisis incluye:

1. An√°lisis de Sentimientos :

- üòä Analizar las rese√±as de Yelp y Google Maps para determinar el sentimiento general (positivo, negativo, neutral).
- üîç Identificar tendencias y patrones en las opiniones de los usuarios.

2. Predicci√≥n de Crecimiento :

- üìà Predecir cu√°les rubros de negocios crecer√°n o decaer√°n.
- üìâ Identificar √°reas de oportunidad o riesgo.

3. Emplazamiento de Nuevos Locales :

- üó∫Ô∏è Determinar las mejores ubicaciones para abrir nuevos locales. basados en an√°lisis de mercado y datos de rese√±as.

4. Sistema de Recomendaci√≥n :

- ü§ñ Desarrollar un sistema que ofrezca recomendaciones personalizadas de restaurantes y otros negocios.
- üåü Permitir a los usuarios descubrir nuevos sabores y experiencias basadas en sus rese√±as previas.

## Descripci√≥n del Conjunto de Datos

- **Diccionario_Datos.ipynb**: Contiene la descripci√≥n detallada de los datos utilizados.
- **Conjunto de Datos**: Incluye rese√±as de usuarios en Google Maps y Yelp sobre los establecimientos que visitan.
  - [**Dataset Google Maps**](https://drive.google.com/drive/folders/1Wf7YkxA0aHI3GpoHc9Nh8_scf5BbD4DA): Incluye la metadata de sitios y reviews de estados de los usuarios.
  - [**Dataset Yelp**](https://drive.google.com/drive/folders/1TI-SsMnZsNP6t930olEEWbBQdo_yuIZF?usp=sharing): Conjunto de datos que contiene:
    - business.pkl
    - checkin.json
    - review.json
    - tip.json
    - user.parquet

Para ver mas informacion, ingresar al [diccionario de datos](https://github.com/bautiarmanicode/HENRY-PROYECTO-FINAL/blob/master/0%20Diccionario_Datos.ipynb)

## Key Performance Indicators (KPis)

1. KPI 1:
2. KPI 2:
3. KPI 3:

## Plan de Trabajo

El trabajo se ha organizado utilizando la metodolog√≠a Gantt para asegurar una distribuci√≥n efectiva de las tareas.

- **Diagrama de Gantt**: Muestra la asignaci√≥n de tareas a cada miembro del equipo y el per√≠odo de tiempo dedicado a cada una.

  tack Tecnol√≥gico

Nuestro proyecto utiliza una combinaci√≥n de tecnolog√≠as y herramientas para garantizar un an√°lisis de datos eficiente y un desarrollo de modelos de machine learning robusto. A continuaci√≥n, se detalla el stack tecnol√≥gico empleado:

### Lenguajes de Programaci√≥n

- **Python**: Utilizado para el an√°lisis de datos, desarrollo de modelos de machine learning y scripting en general.
- **SQL**: Empleado para la gesti√≥n y consulta de bases de datos.

### Bibliotecas y Frameworks

- **Pandas**: Para la manipulaci√≥n y an√°lisis de datos.
- **NumPy**: Para operaciones matem√°ticas y manejo de matrices.
- **Scikit-learn**: Para el desarrollo y evaluaci√≥n de modelos de machine learning.

### Bases de Datos (A√∫n por definir)

- **PostgreSQL**: Utilizado para almacenar y gestionar grandes vol√∫menes de datos estructurados.
- **SQLite**: Empleado para el almacenamiento local durante el desarrollo y pruebas.

### Herramientas de ETL (A√∫n por definir)

- **Apache Airflow**: Para la orquestaci√≥n de flujos de trabajo de datos.
- **Talend**: Utilizado para la integraci√≥n de datos y la ejecuci√≥n de procesos ETL.

### Plataformas de Despliegue

- **Google cloud services**: Utilizado para almacenamiento en la nube, c√≥mputo y servicios de machine
- **Docker**: Para la creaci√≥n de contenedores y la gesti√≥n de entornos de desarrollo consistentes.

### Herramientas de Colaboraci√≥n y Control de Versiones

- **Git**: Para el control de versiones del c√≥digo.
- **GitHub**: Para la colaboraci√≥n en el c√≥digo fuente y la gesti√≥n de repositorios.
- **Trello**: Para la gesti√≥n de proyectos y seguimiento de tareas.
- **Team Gantt**: Para la designaci√≥n de tareas en un tiempo espec√≠fico.

### Otros Servicios y Herramientas

- **Drive**: Para la importaci√≥n de los datos y donde estuvieron los datos alojados inicialmente.
- **Google Maps API**: Para la obtenci√≥n de datos de localizaci√≥n y rese√±as.
- **Yelp API**: Para la obtenci√≥n de datos de rese√±as y metadata de establecimientos.
- **Discord**: Para la comunicaci√≥n interna del equipo, reuniones y videoconferencias.

### Visualizaci√≥n e Interacci√≥n

- **Power BI**: Para la visualizaci√≥n e interacci√≥n del usuario con los KPI's encontrados.

## Sprints

### üèÅSprint 1: Puesta en marcha del proyecto y Trabajo con DatosüèÅ

En este sprint se enfoca en iniciar el proyecto y realizar un an√°lisis preliminar de los datos y las tecnolog√≠as a emplear, con lo que teniendo un entendimiento de lo que se va a lograr encarar la soluci√≥n.

### üèÅSprint 2: Data EngineeringüèÅ

Este sprint se centra en finalizar la infraestructura y pipelines del proyecto, al realizar el proceso ETL apuntando a estructuras de tipo Data Warehouse, Datalake, aprovechando las herramientas de Big Data para su pr√≥xima representaci√≥n en la utilizaci√≥n de los datos.

### üèÅSprint 3: Data Analytics + MLüèÅ

En este √∫ltimo sprint, el objetivo es tener listos los modelos de machine learning y el dashboard interactivo en donde el cliente pueda comprender, visualizar e interactuar con los datos provistos y KPI's para su consumo, y preparar una presentaci√≥n integral del proyecto.

## Pipeline del Proceso ETL

- **Carga Incremental**:
  - Descripci√≥n de los pasos del pipeline ETL.
  - Herramientas y t√©cnicas utilizadas para la carga incremental de datos.

## An√°lisis de los Datos

- Descripci√≥n del an√°lisis realizado:
  - Exploraci√≥n inicial de los datos.
  - Limpieza y preprocesamiento.
  - An√°lisis descriptivo y de tendencias.

## √çndice de Archivos del Repositorio

- Lista de archivos y carpetas importantes del repositorio con una breve descripci√≥n de cada uno.
- .
- .
- .
- .

## Equipo Involucrado

![1720195634242](image/README/1720195634242.png)


### Informaci√≥n sobre los miembros del equipo:

- Nombres y roles:
  - **Bautista Armani**
    - Rol: Data Engineer
    - [LinkedIn](https://www.linkedin.com/in/bautiarmani/)
  - **Adrian Panduro**
    - Rol: Data Engineer
    - [LinkedIn](https://www.linkedin.com/in/adrian-panduro-valdivia-7a1ab5290/)
  - **Lorenzo Locava**
    - Rol: Data Scientist
    - [LinkedIn](https://www.linkedin.com/in/lacavalorenzo/)
  - **Juan Celada**
    - Rol: Data Analyst
    - [LinkedIn](https://www.linkedin.com/in/juan-cruz-celada/)
  - **Jay Peralta**
    - Rol: Data Analyst
    - [LinkedIn](https://www.linkedin.com/in/jayperaltaborjas/)

---
