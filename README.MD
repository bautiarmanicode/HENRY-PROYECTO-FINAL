# Proyecto YELP & GOOGLE MAPS - REVIEWS AND RECOMMENDATIONS
![1718594640848](image/README/1718594640848.png)


## √çndice del Proyecto
1. [Objetivo y Alcance del Proyecto](#objetivo-y-alcance-del-proyecto)
2. [Descripci√≥n del Conjunto de Datos](#descripci√≥n-del-conjunto-de-datos)
3. [Plan de Trabajo](#plan-de-trabajo)
4. [Stack Tecnol√≥gico](#stack-tecnol√≥gico)
5. [Sprints](#sprints)
    - [Sprint 1: Puesta en marcha del proyecto](#sprint-1-puesta-en-marcha-del-proyecto)
    - [Sprint 2: Etapa de analytics y ML](#sprint-2-etapa-de-analytics-y-ml)
    - [Sprint 3: Demo Final](#sprint-3-demo-final)
6. [Pipeline del Proceso ETL](#pipeline-del-proceso-etl)
7. [An√°lisis de los Datos](#an√°lisis-de-los-datos)
8. [Tecnolog√≠as Utilizadas](#tecnolog√≠as-utilizadas)
9. [√çndice de Archivos del Repositorio](#√≠ndice-de-archivos-del-repositorio)
10. [Equipo Involucrado](#equipo-involucrado)

## Objetivo y Alcance del Proyecto

El objetivo de este proyecto es analizar y recomendar establecimientos basados en las rese√±as y datos obtenidos de Yelp y Google Maps. Este an√°lisis incluye:

1. An√°lisis de Sentimientos :
  - üòä Analizar las rese√±as de Yelp y Google Maps para determinar el sentimiento general (positivo, negativo, neutral).
  - üîç Identificar tendencias y patrones en las opiniones de los usuarios.
2. Predicci√≥n de Crecimiento :
  - üìà Predecir cu√°les rubros de negocios crecer√°n o decaer√°n.
  - üìâ Identificar √°reas de oportunidad o riesgo.
3. Emplazamiento de Nuevos Locales :
  - üó∫Ô∏è Determinar las mejores ubicaciones para abrir nuevos locales. basados en an√°lisis de mercado y datos de rese√±as.
4. Sistema de Recomendaci√≥n :
  - ü§ñ Desarrollar un sistema que ofrezca recomendaciones personalizadas de restaurantes y otros negocios.
  - üåü Permitir a los usuarios descubrir nuevos sabores y experiencias basadas en sus rese√±as previas.

## Descripci√≥n del Conjunto de Datos

- **Diccionario_Datos.ipynb**: Contiene la descripci√≥n detallada de los datos utilizados.
- **Conjunto de Datos**: Incluye rese√±as de usuarios en Google Maps y Yelp sobre los establecimientos que visitan.
- [**Dataset Google Maps**](https://drive.google.com/drive/folders/1Wf7YkxA0aHI3GpoHc9Nh8_scf5BbD4DA): Incluye la metadata de sitios y reviews de estados de los usuarios.
- [**Dataset Yelp**](https://drive.google.com/drive/folders/1TI-SsMnZsNP6t930olEEWbBQdo_yuIZF?usp=sharing): Conjunto de datos que contiene:
  - business.pkl
  - checkin.json
  - review.json
  - tip.json
  - user.parquet

## Plan de Trabajo

El trabajo se ha organizado utilizando la metodolog√≠a Gantt para asegurar una distribuci√≥n efectiva de las tareas.

- **Diagrama de Gantt**: Muestra la asignaci√≥n de tareas a cada miembro del equipo y el per√≠odo de tiempo dedicado a cada una.

  ![alt text](image/image.png)

## Stack Tecnol√≥gico

Nuestro proyecto utiliza una combinaci√≥n de tecnolog√≠as y herramientas para garantizar un an√°lisis de datos eficiente y un desarrollo de modelos de machine learning robusto. A continuaci√≥n, se detalla el stack tecnol√≥gico empleado:

### Lenguajes de Programaci√≥n
- **Python**: Utilizado para el an√°lisis de datos, desarrollo de modelos de machine learning y scripting en general.
- **SQL**: Empleado para la gesti√≥n y consulta de bases de datos.

### Bibliotecas y Frameworks
- **Pandas**: Para la manipulaci√≥n y an√°lisis de datos.
- **NumPy**: Para operaciones matem√°ticas y manejo de matrices.
- **Scikit-learn**: Para el desarrollo y evaluaci√≥n de modelos de machine learning.
- **TensorFlow/Keras**: Para la creaci√≥n y entrenamiento de modelos de deep learning.
- **NLTK/Spacy**: Para procesamiento de lenguaje natural (NLP) y an√°lisis de sentimiento.
- **Matplotlib/Seaborn**: Para la visualizaci√≥n de datos.
- **Django/Flask**: Para la creaci√≥n de la API y el backend del proyecto.

### Bases de Datos
- **PostgreSQL**: Utilizado para almacenar y gestionar grandes vol√∫menes de datos estructurados.
- **SQLite**: Empleado para el almacenamiento local durante el desarrollo y pruebas.

### Herramientas de ETL
- **Apache Airflow**: Para la orquestaci√≥n de flujos de trabajo de datos.
- **Talend**: Utilizado para la integraci√≥n de datos y la ejecuci√≥n de procesos ETL.

### Plataformas de Despliegue
- **Google cloud services**: Utilizado para almacenamiento en la nube, c√≥mputo y servicios de machine 
- **Docker**: Para la creaci√≥n de contenedores y la gesti√≥n de entornos de desarrollo consistentes.

### Herramientas de Colaboraci√≥n y Control de Versiones
- **Git**: Para el control de versiones del c√≥digo.
- **GitHub**: Para la colaboraci√≥n en el c√≥digo fuente y la gesti√≥n de repositorios.
- **Trello**: Para la gesti√≥n de proyectos y seguimiento de tareas.
- **Team Gantt**: Para la designaci√≥n de tareas en un tiempo espec√≠fico. 

### Otros Servicios y Herramientas
- **Drive**: Para la importaci√≥n de los datos y donde estuvieron los datos alojados inicialmente.
- **Google Maps API**: Para la obtenci√≥n de datos de localizaci√≥n y rese√±as.
- **Yelp API**: Para la obtenci√≥n de datos de rese√±as y metadata de establecimientos.
- **Discord**: Para la comunicaci√≥n interna del equipo, reuniones y videoconferencias.

### Infraestructura
- **Terraform**: Para la gesti√≥n de la infraestructura como c√≥digo.
- **Kubernetes**: Para la orquestaci√≥n de contenedores y gesti√≥n de aplicaciones escalables.

## Sprints

### üèÅSprint 1: Puesta en marcha del proyecto y Trabajo con DatosüèÅ

En este sprint se enfoca en iniciar el proyecto y realizar un an√°lisis preliminar de los datos y las tecnolog√≠as a emplear.

### üèÅSprint 2: Data EngineeringüèÅ

Este sprint se centra en finalizar la infraestructura del proyecto y en realizar an√°lisis avanzados y desarrollos de machine learning.

### üèÅSprint 3: Data Analytics + MLüèÅ

El objetivo es tener listos los modelos de machine learning y el dashboard, y preparar una presentaci√≥n integral del proyecto.

## Pipeline del Proceso ETL

- **Carga Incremental**:
  - Descripci√≥n de los pasos del pipeline ETL.
  - Herramientas y t√©cnicas utilizadas para la carga incremental de datos.

## An√°lisis de los Datos

- Descripci√≥n del an√°lisis realizado:
  - Exploraci√≥n inicial de los datos.
  - Limpieza y preprocesamiento.
  - An√°lisis descriptivo y de tendencias.

## Tecnolog√≠as Utilizadas

- Detalle de las tecnolog√≠as y herramientas utilizadas:
  - Lenguajes de programaci√≥n.
  - Librer√≠as y frameworks.
  - Plataformas de despliegue.

## √çndice de Archivos del Repositorio

- Lista de archivos y carpetas importantes del repositorio con una breve descripci√≥n de cada uno.

## Equipo Involucrado
![1718648248848](image/README/1718648248848.png)
- Informaci√≥n sobre los miembros del equipo:
  - Nombres y roles.
  - Enlaces a perfiles de LinkedIn.

---
